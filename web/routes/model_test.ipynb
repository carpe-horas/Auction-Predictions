{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 타입: <class 'numpy.ndarray'>\n",
      "파일 내용:\n",
      "[9.35255831e+05 8.79858156e+00 1.39610475e+01 3.93226041e+00\n",
      " 1.16099482e+09 9.22900946e+02 4.56147102e-02 4.40991734e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 경로 설정\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler.npy\"\n",
    "\n",
    "# 파일 로드\n",
    "scaler_data = np.load(scaler_path, allow_pickle=True)\n",
    "\n",
    "# 파일 형식 및 내용 출력\n",
    "print(f\"파일 타입: {type(scaler_data)}\")\n",
    "print(f\"파일 내용:\\n{scaler_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Scaler Parameters: {'mean': [935255.831, 8.79858156, 13.9610475, 3.93226041], 'scale': [1160994820.0, 922.900946, 0.0456147102, 0.440991734]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 스케일러 생성 및 예제 데이터\n",
    "scaler = StandardScaler()\n",
    "scaler.mean_ = [9.35255831e+05, 8.79858156e+00, 1.39610475e+01, 3.93226041e+00]\n",
    "scaler.scale_ = [1.16099482e+09, 9.22900946e+02, 4.56147102e-02, 4.40991734e-01]\n",
    "\n",
    "SCALER_PATH = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler2.npy\"\n",
    "\n",
    "# 딕셔너리 형식으로 저장\n",
    "scaler_params = {'mean': scaler.mean_, 'scale': scaler.scale_}\n",
    "np.save(SCALER_PATH, scaler_params)\n",
    "\n",
    "# 저장 확인\n",
    "loaded_params = np.load(SCALER_PATH, allow_pickle=True).item()\n",
    "print(f\"Saved Scaler Parameters: {loaded_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shape: 4\n",
      "Scale shape: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 스케일러 파일 경로\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler2.npy\"\n",
    "\n",
    "try:\n",
    "    # 스케일러 파일 로드\n",
    "    scaler_params = np.load(scaler_path, allow_pickle=True).item()\n",
    "\n",
    "    # Mean과 Scale의 길이 출력\n",
    "    print(\"Mean shape:\", len(scaler_params['mean']))\n",
    "    print(\"Scale shape:\", len(scaler_params['scale']))\n",
    "except Exception as e:\n",
    "    print(f\"스케일러 파일을 로드하는 중 오류가 발생했습니다: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케일러 재학습 완료. 파일이 저장되었습니다: C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler_correct.npy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 예제 데이터프레임 생성 (필요한 특성만 포함)\n",
    "data = pd.DataFrame({\n",
    "    'average_price': [1000, 2000, 1500],\n",
    "    'total_quantity': [300, 400, 500]\n",
    "})\n",
    "\n",
    "# 스케일러 생성 및 학습\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "\n",
    "# 새로운 스케일러 저장\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler_correct.npy\"\n",
    "np.save(scaler_path, {'mean': scaler.mean_, 'scale': scaler.scale_})\n",
    "print(\"스케일러 재학습 완료. 파일이 저장되었습니다:\", scaler_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shape: 2\n",
      "Scale shape: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler_correct.npy\"\n",
    "\n",
    "# 파일 로드\n",
    "scaler_data = np.load(scaler_path, allow_pickle=True).item()\n",
    "print(\"Mean shape:\", len(scaler_data['mean']))\n",
    "print(\"Scale shape:\", len(scaler_data['scale']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케일러 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 현재 작업 디렉토리 설정 (Jupyter Notebook에서는 __file__ 대신 os.getcwd() 사용)\n",
    "current_dir = os.getcwd()  # 현재 Jupyter Notebook 실행 디렉토리\n",
    "services_dir = os.path.abspath(os.path.join(current_dir, '..', 'services'))\n",
    "sys.path.append(services_dir)\n",
    "\n",
    "# db_connection 가져오기\n",
    "from db_connection import get_db_connection\n",
    "\n",
    "# DB 연결\n",
    "engine = get_db_connection()\n",
    "\n",
    "# 특성 컬럼 정의\n",
    "feature_columns = [\n",
    "    'average_price', 'total_quantity', 'temperature_range', 'average_temperature', \n",
    "    'daily_rainfall', 'sales_amount', 'quantity_price_ratio', 'price_volatility', \n",
    "    'quantity_volatility'\n",
    "]\n",
    "\n",
    "# 데이터 가져오기\n",
    "query = f\"SELECT {', '.join(feature_columns)} FROM clustered_seoul\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# 데이터 검증\n",
    "if df.empty:\n",
    "    raise ValueError(\"데이터베이스에서 데이터를 가져올 수 없습니다.\")\n",
    "\n",
    "# NaN 값 처리\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# 스케일러 학습\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[feature_columns])\n",
    "\n",
    "# 스케일러 저장\n",
    "scaler_data = {\n",
    "    'mean': scaler.mean_,\n",
    "    'scale': scaler.scale_\n",
    "}\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/lstm_clustering/scaler_correct.npy\"\n",
    "np.save(scaler_path, scaler_data)\n",
    "\n",
    "print(\"스케일러 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 타입: <class 'dict'>\n",
      "스케일러 데이터 내용: {'mean': array([2.13612153e+05, 8.78196386e+00, 1.48965122e+01, 4.11544383e+00,\n",
      "       1.05811652e+09, 5.61552449e+01, 5.96235153e-02, 1.08156004e+00]), 'scale': array([2.66358094e+05, 3.04800166e+00, 1.01645047e+01, 1.43049623e+01,\n",
      "       1.12352734e+09, 9.61063535e+01, 9.24607830e-01, 2.54703718e+01])}\n",
      "스케일러 mean: [2.13612153e+05 8.78196386e+00 1.48965122e+01 4.11544383e+00\n",
      " 1.05811652e+09 5.61552449e+01 5.96235153e-02 1.08156004e+00]\n",
      "스케일러 scale: [2.66358094e+05 3.04800166e+00 1.01645047e+01 1.43049623e+01\n",
      " 1.12352734e+09 9.61063535e+01 9.24607830e-01 2.54703718e+01]\n",
      "Mean shape: 8\n",
      "Scale shape: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/LSTM/cluster_1_units_100_dropout_0.3_epochs_100_batch_64/scaler.npy\"\n",
    "\n",
    "# 파일 로드\n",
    "scaler_data = np.load(scaler_path, allow_pickle=True).item()  # 딕셔너리로 불러오기\n",
    "print(f\"파일 타입: {type(scaler_data)}\")\n",
    "print(\"스케일러 데이터 내용:\", scaler_data)\n",
    "print(\"스케일러 mean:\", scaler_data['mean'])\n",
    "print(\"스케일러 scale:\", scaler_data['scale'])\n",
    "print(\"Mean shape:\", len(scaler_data['mean']))\n",
    "print(\"Scale shape:\", len(scaler_data['scale']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 타입: <class 'dict'>\n",
      "스케일러 데이터 내용: {'mean': array([2.13612153e+05, 8.78196386e+00, 1.48965122e+01, 4.11544383e+00,\n",
      "       1.05811652e+09, 5.61552449e+01, 5.96235153e-02, 1.08156004e+00,\n",
      "       2.57187745e-01, 2.05498822e-01, 2.54202671e-01, 2.83110762e-01]), 'scale': array([2.66358094e+05, 3.04800166e+00, 1.01645047e+01, 1.43049623e+01,\n",
      "       1.12352734e+09, 9.61063535e+01, 9.24607830e-01, 2.54703718e+01,\n",
      "       4.37083755e-01, 4.04065658e-01, 4.35412073e-01, 4.50509776e-01])}\n",
      "스케일러 mean: [2.13612153e+05 8.78196386e+00 1.48965122e+01 4.11544383e+00\n",
      " 1.05811652e+09 5.61552449e+01 5.96235153e-02 1.08156004e+00\n",
      " 2.57187745e-01 2.05498822e-01 2.54202671e-01 2.83110762e-01]\n",
      "스케일러 scale: [2.66358094e+05 3.04800166e+00 1.01645047e+01 1.43049623e+01\n",
      " 1.12352734e+09 9.61063535e+01 9.24607830e-01 2.54703718e+01\n",
      " 4.37083755e-01 4.04065658e-01 4.35412073e-01 4.50509776e-01]\n",
      "Mean shape: 12\n",
      "Scale shape: 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaler_path = \"C:/Users/carpe/OneDrive/Desktop/workspace/project/Aution/Auction/saved_models/LSTM/cluster_1_units_100_dropout_0.3_epochs_100_batch_64/scaler.npy\"\n",
    "\n",
    "# 파일 로드\n",
    "scaler_data = np.load(scaler_path, allow_pickle=True).item()  # 딕셔너리로 불러오기\n",
    "print(f\"파일 타입: {type(scaler_data)}\")\n",
    "print(\"스케일러 데이터 내용:\", scaler_data)\n",
    "print(\"스케일러 mean:\", scaler_data['mean'])\n",
    "print(\"스케일러 scale:\", scaler_data['scale'])\n",
    "print(\"Mean shape:\", len(scaler_data['mean']))\n",
    "print(\"Scale shape:\", len(scaler_data['scale']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
